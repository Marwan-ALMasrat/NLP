import streamlit as st
import pandas as pd
from wordcloud import WordCloud
import io
import base64
from PIL import Image
import json
import os

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ù…Ø®ØµØµØ©
try:
    from utils.text_classifier import NewsClassifier
    from utils.text_summarizer import TextSummarizer
    from utils.entity_extractor import EntityExtractor
except ImportError as e:
    st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„ÙˆØ­Ø¯Ø§Øª: {e}")
    st.stop()

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
st.set_page_config(
    page_title="Ù…Ø­Ù„Ù„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø°ÙƒÙŠ",
    page_icon="ğŸ“°",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ØªØ­Ù…ÙŠÙ„ CSS Ù…Ø®ØµØµ
def load_css():
    st.markdown("""
    <style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        color: #1E88E5;
        margin-bottom: 2rem;
    }
    
    .feature-box {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
        border-left: 5px solid #1E88E5;
    }
    
    .metric-card {
        background-color: white;
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        text-align: center;
    }
    
    .success-box {
        background-color: #d4edda;
        color: #155724;
        padding: 1rem;
        border-radius: 5px;
        border: 1px solid #c3e6cb;
    }
    
    .warning-box {
        background-color: #fff3cd;
        color: #856404;
        padding: 1rem;
        border-radius: 5px;
        border: 1px solid #ffeaa7;
    }
    </style>
    """, unsafe_allow_html=True)

load_css()

# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¬Ù„Ø³Ø©
@st.cache_resource
def initialize_models():
    """ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
    try:
        classifier = NewsClassifier()
        summarizer = TextSummarizer()
        extractor = EntityExtractor()
        return classifier, summarizer, extractor
    except Exception as e:
        st.error(f"ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬: {e}")
        return None, None, None

# Ø¯Ø§Ù„Ø© Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø®Ø·Ø·Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Streamlit Ø§Ù„Ù…Ø¯Ù…Ø¬
def create_streamlit_chart(data, chart_type="bar", title=""):
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø®Ø·Ø· Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø®Ø·Ø·Ø§Øª Streamlit Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©"""
    st.subheader(title)
    
    if isinstance(data, dict):
        data = pd.DataFrame(list(data.items()), columns=['Category', 'Count'])
    
    if chart_type == "bar":
        st.bar_chart(data.set_index('Category') if 'Category' in data.columns else data)
    elif chart_type == "line":
        st.line_chart(data.set_index('Category') if 'Category' in data.columns else data)
    elif chart_type == "area":
        st.area_chart(data.set_index('Category') if 'Category' in data.columns else data)
    else:
        # Default to bar chart
        st.bar_chart(data.set_index('Category') if 'Category' in data.columns else data)

# Ø¯Ø§Ù„Ø© Ù„Ø¹Ø±Ø¶ WordCloud
def display_wordcloud(text, title="Ø³Ø­Ø§Ø¨Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª"):
    """Ø¹Ø±Ø¶ Ø³Ø­Ø§Ø¨Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª"""
    try:
        wordcloud = WordCloud(
            width=800, 
            height=400, 
            background_color='white',
            font_path=None,  # Ù‚Ø¯ ØªØ­ØªØ§Ø¬ Ù„ØªØ¹Ø¯ÙŠÙ„ Ù‡Ø°Ø§ Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
            max_words=100
        ).generate(text)
        
        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØµÙˆØ±Ø©
        img = wordcloud.to_image()
        st.subheader(title)
        st.image(img, use_column_width=True)
        
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø­Ø§Ø¨Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª: {e}")

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
classifier, summarizer, extractor = initialize_models()

# Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
st.markdown('<h1 class="main-header">ğŸ“° Ù…Ø­Ù„Ù„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø°ÙƒÙŠ</h1>', unsafe_allow_html=True)
st.markdown("---")

# Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
st.sidebar.title("ğŸ›ï¸ Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…")
st.sidebar.markdown("---")

# Ø§Ø®ØªÙŠØ§Ø± Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„
analysis_type = st.sidebar.selectbox(
    "Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„",
    ["ØªØµÙ†ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ", "ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†ØµÙˆØµ", "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª", "ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„"]
)

# Ø®ÙŠØ§Ø±Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
st.sidebar.markdown("### âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
show_confidence = st.sidebar.checkbox("Ø¹Ø±Ø¶ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©", True)
show_stats = st.sidebar.checkbox("Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª", True)
show_visualizations = st.sidebar.checkbox("Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø®Ø·Ø·Ø§Øª", True)

st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ“Š Ø­ÙˆÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚")
st.sidebar.info(
    """
    **Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª:**
    - ØªØµÙ†ÙŠÙ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¥Ù„Ù‰ ÙØ¦Ø§Øª Ù…Ø®ØªÙ„ÙØ©
    - ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø·ÙˆÙŠÙ„Ø©
    - Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³Ù…Ø§Ø©
    - ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„Ù†ØµÙˆØµ
    - Ø³Ø­Ø§Ø¨Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª
    - Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ØªÙØµÙŠÙ„ÙŠØ©
    """
)

# Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
col1, col2 = st.columns([2, 1])

with col1:
    st.header("ğŸ“ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù†Øµ")
    
    # Ø®ÙŠØ§Ø±Ø§Øª Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù†Øµ
    input_method = st.radio(
        "Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„:",
        ["ÙƒØªØ§Ø¨Ø© Ù…Ø¨Ø§Ø´Ø±Ø©", "Ø±ÙØ¹ Ù…Ù„Ù Ù†ØµÙŠ", "URL"]
    )
    
    user_text = ""
    
    if input_method == "ÙƒØªØ§Ø¨Ø© Ù…Ø¨Ø§Ø´Ø±Ø©":
        user_text = st.text_area(
            "Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ù„Ù„ØªØ­Ù„ÙŠÙ„:",
            height=300,
            placeholder="Ø§ÙƒØªØ¨ Ø£Ùˆ Ø§Ù„ØµÙ‚ Ø§Ù„Ù†Øµ Ù‡Ù†Ø§..."
        )
    
    elif input_method == "Ø±ÙØ¹ Ù…Ù„Ù Ù†ØµÙŠ":
        uploaded_file = st.file_uploader(
            "Ø§Ø®ØªØ± Ù…Ù„Ù Ù†ØµÙŠ",
            type=['txt', 'docx', 'pdf']
        )
        if uploaded_file is not None:
            try:
                if uploaded_file.type == "text/plain":
                    user_text = str(uploaded_file.read(), "utf-8")
                else:
                    st.warning("ÙŠØªÙ… Ø¯Ø¹Ù… Ù…Ù„ÙØ§Øª .txt ÙÙ‚Ø· Ø­Ø§Ù„ÙŠØ§")
            except Exception as e:
                st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {e}")
    
    elif input_method == "URL":
        url = st.text_input("Ø£Ø¯Ø®Ù„ Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ù‚Ø§Ù„:")
        if url and st.button("Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† URL"):
            try:
                # Ù‡Ù†Ø§ ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© ÙƒÙˆØ¯ Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† URL
                st.info("Ù‡Ø°Ù‡ Ø§Ù„Ù…ÙŠØ²Ø© Ù‚ÙŠØ¯ Ø§Ù„ØªØ·ÙˆÙŠØ±")
            except Exception as e:
                st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ: {e}")

with col2:
    st.header("ğŸ“Š Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø³Ø±ÙŠØ¹Ø©")
    
    if user_text:
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø£Ø³Ø§Ø³ÙŠØ©
        word_count = len(user_text.split())
        char_count = len(user_text)
        sentence_count = len([s for s in user_text.split('.') if s.strip()])
        
        st.metric("Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª", word_count)
        st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù", char_count)
        st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø¬Ù…Ù„", sentence_count)
        
        # ØªÙ‚ÙŠÙŠÙ… Ø³Ù‡ÙˆÙ„Ø© Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© (ØªÙ‚Ø±ÙŠØ¨ÙŠ)
        avg_words_per_sentence = word_count / max(sentence_count, 1)
        if avg_words_per_sentence < 15:
            readability = "Ø³Ù‡Ù„"
            color = "green"
        elif avg_words_per_sentence < 25:
            readability = "Ù…ØªÙˆØ³Ø·"
            color = "orange"
        else:
            readability = "ØµØ¹Ø¨"
            color = "red"
        
        st.markdown(f"**Ø³Ù‡ÙˆÙ„Ø© Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©:** <span style='color: {color}'>{readability}</span>", 
                   unsafe_allow_html=True)

# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„
if user_text and st.button("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„", type="primary"):
    
    with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„..."):
        
        if analysis_type == "ØªØµÙ†ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ":
            st.header("ğŸ·ï¸ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØµÙ†ÙŠÙ")
            
            if classifier:
                try:
                    result = classifier.classify(user_text)
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.success(f"**Ø§Ù„ÙØ¦Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©:** {result.get('category', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")
                        
                        if show_confidence and 'confidence' in result:
                            confidence = result['confidence']
                            st.progress(confidence)
                            st.write(f"Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©: {confidence:.2%}")
                    
                    with col2:
                        if show_visualizations and 'probabilities' in result:
                            prob_data = pd.DataFrame(
                                list(result['probabilities'].items()),
                                columns=['Category', 'Probability']
                            )
                            st.subheader("ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª")
                            st.bar_chart(prob_data.set_index('Category'))
                            
                except Exception as e:
                    st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØµÙ†ÙŠÙ: {e}")
            else:
                st.error("Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØµÙ†ÙŠÙ ØºÙŠØ± Ù…ØªØ§Ø­")
        
        elif analysis_type == "ØªÙ„Ø®ÙŠØµ Ø§Ù„Ù†ØµÙˆØµ":
            st.header("ğŸ“„ Ù…Ù„Ø®Øµ Ø§Ù„Ù†Øµ")
            
            if summarizer:
                try:
                    summary = summarizer.summarize(user_text)
                    
                    col1, col2 = st.columns([2, 1])
                    
                    with col1:
                        st.markdown("### Ø§Ù„Ù…Ù„Ø®Øµ:")
                        st.write(summary.get('summary', 'Ù„Ù… ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ø®Øµ'))
                    
                    with col2:
                        if show_stats:
                            original_length = len(user_text.split())
                            summary_length = len(summary.get('summary', '').split())
                            compression_ratio = (1 - summary_length/original_length) * 100 if original_length > 0 else 0
                            
                            st.metric("Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ø£ØµÙ„ÙŠ", f"{original_length} ÙƒÙ„Ù…Ø©")
                            st.metric("Ø·ÙˆÙ„ Ø§Ù„Ù…Ù„Ø®Øµ", f"{summary_length} ÙƒÙ„Ù…Ø©")
                            st.metric("Ù†Ø³Ø¨Ø© Ø§Ù„Ø¶ØºØ·", f"{compression_ratio:.1f}%")
                            
                except Exception as e:
                    st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ„Ø®ÙŠØµ: {e}")
            else:
                st.error("Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªÙ„Ø®ÙŠØµ ØºÙŠØ± Ù…ØªØ§Ø­")
        
        elif analysis_type == "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª":
            st.header("ğŸ” Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©")
            
            if extractor:
                try:
                    entities = extractor.extract(user_text)
                    
                    if entities:
                        # Ø¹Ø±Ø¶ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª ÙÙŠ Ø¬Ø¯ÙˆÙ„
                        entities_df = pd.DataFrame(entities)
                        st.dataframe(entities_df)
                        
                        if show_visualizations:
                            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª
                            entity_counts = entities_df['label'].value_counts()
                            st.subheader("ØªÙˆØ²ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª")
                            st.bar_chart(entity_counts)
                    else:
                        st.info("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙƒÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„Ù†Øµ")
                        
                except Exception as e:
                    st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª: {e}")
            else:
                st.error("Ù†Ù…ÙˆØ°Ø¬ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ØªØ§Ø­")
        
        elif analysis_type == "ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„":
            st.header("ğŸ” Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„")
            
            # ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„
            tabs = st.tabs(["Ø§Ù„ØªØµÙ†ÙŠÙ", "Ø§Ù„ØªÙ„Ø®ÙŠØµ", "Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª", "Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¥Ø¶Ø§ÙÙŠØ©"])
            
            with tabs[0]:
                if classifier:
                    try:
                        result = classifier.classify(user_text)
                        st.success(f"**Ø§Ù„ÙØ¦Ø©:** {result.get('category', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")
                        if 'confidence' in result:
                            st.progress(result['confidence'])
                    except Exception as e:
                        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØµÙ†ÙŠÙ: {e}")
            
            with tabs[1]:
                if summarizer:
                    try:
                        summary = summarizer.summarize(user_text)
                        st.write(summary.get('summary', 'Ù„Ù… ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ø®Øµ'))
                    except Exception as e:
                        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ„Ø®ÙŠØµ: {e}")
            
            with tabs[2]:
                if extractor:
                    try:
                        entities = extractor.extract(user_text)
                        if entities:
                            st.dataframe(pd.DataFrame(entities))
                        else:
                            st.info("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙƒÙŠØ§Ù†Ø§Øª")
                    except Exception as e:
                        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª: {e}")
            
            with tabs[3]:
                # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¥Ø¶Ø§ÙÙŠØ©
                words = user_text.split()
                word_freq = pd.Series(words).value_counts().head(10)
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("Ø£ÙƒØ«Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª ØªÙƒØ±Ø§Ø±Ø§Ù‹")
                    st.bar_chart(word_freq)
                
                with col2:
                    if show_visualizations:
                        display_wordcloud(user_text)

# Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
st.markdown("---")
st.markdown("### ğŸ’¡ Ù†ØµØ§Ø¦Ø­ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…")
with st.expander("Ø§Ø¶ØºØ· Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù†ØµØ§Ø¦Ø­"):
    st.markdown("""
    - **Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:** Ø§Ø³ØªØ®Ø¯Ù… Ù†ØµÙˆØµ ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…ÙƒØªÙ…Ù„Ø©
    - **Ø§Ù„ØªØµÙ†ÙŠÙ:** ÙŠØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„ Ù…Ø¹ Ø§Ù„Ù…Ù‚Ø§Ù„Ø§Øª Ø§Ù„Ø¥Ø®Ø¨Ø§Ø±ÙŠØ© Ø§Ù„ÙƒØ§Ù…Ù„Ø©
    - **Ø§Ù„ØªÙ„Ø®ÙŠØµ:** Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø·ÙˆÙŠÙ„Ø© (Ø£ÙƒØ«Ø± Ù…Ù† 100 ÙƒÙ„Ù…Ø©)
    - **Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª:** ÙŠØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø´Ø®Ø§ØµØŒ Ø§Ù„Ø£Ù…Ø§ÙƒÙ†ØŒ ÙˆØ§Ù„Ù…Ù†Ø¸Ù…Ø§Øª
    - **Ø§Ù„Ø£Ø¯Ø§Ø¡:** Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ø¶Ø¹ Ø«ÙˆØ§Ù† Ø­Ø³Ø¨ Ø·ÙˆÙ„ Ø§Ù„Ù†Øµ
    """)

st.markdown("---")
st.markdown("**ØªÙ… ØªØ·ÙˆÙŠØ±Ù‡ Ø¨ÙˆØ§Ø³Ø·Ø©:** ÙØ±ÙŠÙ‚ ØªØ·ÙˆÙŠØ± Ù…Ø­Ù„Ù„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø°ÙƒÙŠ")
